・過学習とは、テスト誤差（検証用データに対する誤差）と訓練誤差とで学習曲線が乖離すること。
→過学習が起きる前にトレーニングをやめると良い
・入力値が小さいのに、NN（パラメータ数やノード数）が大きい（ネットワークの自由度が高い）と過学習が起きる。

過学習を抑えるために正則化手法を利用して、ネットワークの自由度をそぐ！
・L1正則化、L2正則化、ドロップアウト

・正則化ではWeightdecay（荷重減衰）を行う。
・重みが大きい値を取ることで過学習が発生することがあるため
解決するために、誤差に対して正則化項を加算することで、重みを抑制
（重みをコントロールしつつ、重みの大きさにバランスを出す必要）

・誤差関数にpノルムを加える。p=1(マンハッタン距離),p=2(ユーグリッド距離)の場合は下記
・L1正則化（ラッソ回帰）
・L2正則化（リッジ回帰）
→L1正則化だとスパース化できる。

・ドロップアウトとはランダムにノードを削除して学習させること
データ量を変化させずに、異なるモデルを学習させていると解釈できる
