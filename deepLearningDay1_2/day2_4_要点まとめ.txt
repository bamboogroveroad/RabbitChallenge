・CNNとは、画像の識別や処理を行う時に良く用いられるNN。
・CNNは、汎用性があり、次元的に繋がりのあるデータであれば画像以外にも利用可能。
・単一チャンネル、複数チャネル（1次元〜3次元）のデータ例について。
（## 1か所の場所に複数データがあるものを複数チャネルという）
・画像のCNNの構造図は下記
入力層（画像）→畳み込み層→畳み込み層→プーリング層→畳み込み層→畳み込み層→プーリング層→全結合層→出力層（画像）
・LeNet（CNNの代表的なもの）は、32*32=1024を入力にとって、最終的に10種類に出力する。
以下、流れ
1)Convolutionsで、入力の1024を、28*28*6=4704にする。（6：各人が感想を言うのイメージ）
2)subsamplingで、14*14*6=1176に要約する。
3)Convolutionsで、10*10*16=1600にする。（16：各人が感想を言うのイメージ）
4)subsamplingで、5*5*16=400に要約する。
5)Full connectionで120（感想をまとめるイメージ）、84、最終的に10種類に出力する。

畳み込み層（Convolutions）について
・入力値に対して、フィルター（全結合でいう所の重み）をかけて出力値を得る。
（＊フィルターをかける際は、少しづつ（右→下）ずらしながら、周りとのつながりのある出力値を得る。）
・上記出力値にバイアスを加えて、活性化関数をかけて、最後の出力値を得る。

全結合層について
・いままでNNで勉強してきたものは全部これに該当する。

→まとめると、全結合層の前までは、次元のつながりを保った特徴を抽出、
最後に全結合層で人間が欲しい結果を得る。

・畳み込み層では、画像の場合、縦、横、チャンネル（RGB）の３次元のデータをそのまま学習し、次に伝えることができる。
結論：3次元の空間情報も学習できるような層が畳み込み層である。

・畳み込みの演算概念：バイアス
フィルターは、個性であり、値は全結合でいう重みである。フィルターは複数あってもよい。
最後にバイアスを加えて、画像を出力する。

・畳み込みの演算概念：パディング
入力画像のデータを上下左右に何ピクセルか広げる。
※広げた時に入れるデータは0をいれる、一番近くのデータを入れる。
→フィルタ通過後の出力画像を入力画像とそろえることができる。

・畳み込みの演算概念：ストライド
フィルタの移動する大きさのこと

・畳み込みの演算概念：チャンネル
フィルタの数

全結合層のデメリット
画像の場合、縦、横、チャンネルの３次元データだが、１次元データとして処理される。
→RGBの各チャンネル間の関連性が、学習に反映されないということ。

実際のプログラムでは、計算の効率化のために下記を利用して変換を行う。
im2col 畳み込み演算を効率的に行うために、データをまとめて再編成するアルゴリズム。

・プーリング層は重みをもたないで処理を行う。
MaxPooling,AvgPooling
→少しづつ（右→下）ずらしながら、それぞれ最大値、平均値を出力する。

・出力画像のサイズを算出する公式について
(（画像の高さ ＋ 2 * パディング高 - フィルタ高さ）/　ストライド　) + 1
(（画像の幅 ＋ 2 * パディング幅 - フィルタ幅）/　ストライド　) + 1
