・NNにおいて、次の層への出力の大きさを決める非線形の関数。非線形であることが大切。
・入力値の値によって、次の層への信号のON/OFFや強弱を定める働きを持つ。
・線形な関数は加法性、斉次性を満たし、式変換が容易。
・非線形な関数は加法性、斉次性を満たさない。
・メインの線形な処理に非線形な処理をかけることで、バラエティーが増え性能が良くなる。
・中間層用と出力層用の活性化関数がある。
・中間層用の活性化関数について
・ステップ関数は、0未満だと0を出力、0以上だと1を出力する。
⇒線形分離可能なものしか学習できない課題があり、あまり使われていない。
・シグモイド関数は、0〜1の間をなだらかに変化する関数で、信号の強弱を伝えられるようになり普及した。
⇒勾配消失問題を引き起こす。
・Relu関数は、0以下だと0を出力、0より大きいとxを出力する。
⇒勾配消失問題の回避とスパース化に貢献することで良い成果。いま最も使用されている。