●分散深層学習
・多くのデータを使用したり、パラメータ調整のために多くの時間を
使用したりするため、高速な計算が求められる。

・複数のワーカーを使用して、並列的にNNを構成することで効率の良い学習を行いたい。
・高速技術も不可欠である。

軽量化・高速化技術としては下記がある。

データ並列、モデル並列、GPU
→モデルをいかに早く学習するか（高速化）

量子化、蒸留、プルーニング
→性能が悪いPC上でもモデルを動かせるようにする。（軽量化）

●データ並列化
・親モデルを各ワーカーに子モデルとしてコピー
・データ分割し、各ワーカー（別のPC、一台の中に複数のGPU）毎に計算させる。
(データ並列化は複数のPCで行うことが多い。)

・学習をさせた時にモデルに反映させるタイミングの取り方が2つある。同期型、非同期型
〇同期型：同期型のパラメータ更新の流れ。各ワーカーが計算が終わるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する。それを子モデルとしてコピー。
〇非同期型：非同期型のパラメータ更新の流れ。各ワーカーはお互いの計算を待たず、各子モデルごとに更新を行う。
学習が終わった子モデルはパラメータサーバにPushされる。新たに学習を始める時は、パラメータサーバからPopしたモデルに対して学習していく。

同期型と非同期型の比較
・処理のスピードは、お互いのワーカーの計算を待たない非同期型の方が早い。
・非同期型は最新のモデルのパラメータを利用できないので、学習が不安定になりやすい。-> Stale Gradient Problem
・現在は同期型の方が精度が良いことが多いので、主流となっている。（ただし、制御できる環境がない場合は非同期型を利用すことも。）


●モデル並列化
・親モデルを各ワーカーに分割（フローの前後や、分岐のの区切り等で分割）し、それぞれのモデルを学習させる。
全てのデータで学習が終わった後で、一つのモデルに復元。
・モデルが大きい時はモデル並列化を、データが大きい時はデータ並列化をすると良い。
(モデル並列化は1台のPCで複数のGPUで行うことが多い。機械間の通信負荷軽減のため)
・モデルのパラメータ数が多いほど、スピードアップの効率も向上する。

参照論文について
・Large Scale Distributed Deep Networks （Google社が2016年に出した論文、Tensorflowの前身）
・並列コンピューティングを用いることで大規模ネットワークを高速に学習させる仕組みを提案。
・主にモデル並列とデータ並列(非同期型)の提案をしている

●GPUによる高速化

・GPGPU
元々の使用目的であるグラフィック以外の用途で使用されるGPUの総称
→GPGPUの開発環境としては、GUDAが代表的（NVIDIA社が開発しているGPUで使用可能）

・CPU
高性能なコアが少数、複雑で連続的な処理が得意

・GPU
GPUは、比較的低性能なコアが多数、簡単な並列処理が得意、
NNの学習は単純な行列演算が多いので、高速化が可能

●量子化（Quantization）
ネットワークが大きくなると大量のパラメータが必要になり学習や推論に多くのメモリと演算処理が必要

→通常のパラメータの64bit浮動小数点を32bit等の下位の精度に落とすことでメモリと演算処理の削減を行う技術

・量子化の利点と欠点
利点　計算の高速化、省メモリ化
欠点　精度の低下

・精度は低下するが、倍精度を単精度にしてもほぼ精度は変わらない。

●蒸留
学習済みの精度の高いモデルの知識を使い、（計算コストの低い）軽量なモデルの作成を行う技術

・蒸留は教師モデルと生徒モデルの2つで構成される
教師モデル　予測精度の高い、複雑なモデルやアンサンブルされたモデル（レイヤー数多い）
生徒モデル　教師モデルをもとに作られる軽量なモデル（レイヤー数抑える）

・具体的な方法は下記
教師モデルの重みを固定し（学習済み）、生徒モデルの重みを更新していく
誤差は教師モデルと生徒モデルのそれぞれの誤差を使い重みを更新していく

●プルーニング
ネットワークが大きくなると大量のパラメータになるがすべてのニューロンの計算が精度に寄与しているわけではない
→モデルの精度に寄与が少ないニューロンを削減、モデルの圧縮をすることでモデルの軽量化、高速化が見込まれる。
この技術をプルーニングという。

・ニューロンの削減の手法は重みが閾値以下の場合、ニューロンの削除を行い再学習を行う。
例）重みが0.1以下のニューロンを削除

