{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"3_1_simple_RNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"8cNl2QA_Rnv5"},"source":["# 準備"]},{"cell_type":"markdown","metadata":{"id":"YkwjN1jNVAYy"},"source":["## Googleドライブのマウント"]},{"cell_type":"code","metadata":{"id":"pvFXpiH3EVC1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626407660707,"user_tz":-540,"elapsed":27912,"user":{"displayName":"横路岳彦","photoUrl":"","userId":"02779192865702045545"}},"outputId":"f845993a-4e51-41d0-8ff3-eaf6111b4346"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Ub7RYdeY6pK"},"source":["## sys.pathの設定"]},{"cell_type":"markdown","metadata":{"id":"oql7L19rEsWi"},"source":["以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"]},{"cell_type":"code","metadata":{"id":"7Ic2JzkvFX59","executionInfo":{"status":"ok","timestamp":1626407668016,"user_tz":-540,"elapsed":247,"user":{"displayName":"横路岳彦","photoUrl":"","userId":"02779192865702045545"}}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/DNN_code')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"feXB1SiLP4OL"},"source":["# simple RNN\n","### バイナリ加算"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"tzSWNYwxP4OM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1626407685358,"user_tz":-540,"elapsed":12347,"user":{"displayName":"横路岳彦","photoUrl":"","userId":"02779192865702045545"}},"outputId":"e52f5967-57cb-4eb4-a99d-e5cb185c5209"},"source":["import numpy as np\n","from common import functions\n","import matplotlib.pyplot as plt\n","\n","# def d_tanh(x):\n","\n","\n","\n","# データを用意\n","# 2進数の桁数\n","binary_dim = 8\n","# 最大値 + 1\n","largest_number = pow(2, binary_dim)\n","# largest_numberまで2進数を用意\n","binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n","\n","input_layer_size = 2\n","hidden_layer_size = 16\n","output_layer_size = 1\n","\n","weight_init_std = 1\n","learning_rate = 0.1\n","\n","iters_num = 10000\n","plot_interval = 100\n","\n","# ウェイト初期化 (バイアスは簡単のため省略)\n","W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n","W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n","W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n","\n","# Xavier\n","\n","\n","# He\n","\n","\n","\n","# 勾配\n","W_in_grad = np.zeros_like(W_in)\n","W_out_grad = np.zeros_like(W_out)\n","W_grad = np.zeros_like(W)\n","\n","u = np.zeros((hidden_layer_size, binary_dim + 1))\n","z = np.zeros((hidden_layer_size, binary_dim + 1))\n","y = np.zeros((output_layer_size, binary_dim))\n","\n","delta_out = np.zeros((output_layer_size, binary_dim))\n","delta = np.zeros((hidden_layer_size, binary_dim + 1))\n","\n","all_losses = []\n","\n","for i in range(iters_num):\n","    \n","    # A, B初期化 (a + b = d)\n","    a_int = np.random.randint(largest_number/2)\n","    a_bin = binary[a_int] # binary encoding\n","    b_int = np.random.randint(largest_number/2)\n","    b_bin = binary[b_int] # binary encoding\n","    \n","    # 正解データ\n","    d_int = a_int + b_int\n","    d_bin = binary[d_int]\n","    \n","    # 出力バイナリ\n","    out_bin = np.zeros_like(d_bin)\n","    \n","    # 時系列全体の誤差\n","    all_loss = 0    \n","    \n","    # 時系列ループ\n","    for t in range(binary_dim):\n","        # 入力値\n","        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n","        # 時刻tにおける正解データ\n","        dd = np.array([d_bin[binary_dim - t - 1]])\n","        \n","        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n","        z[:,t+1] = functions.sigmoid(u[:,t+1])\n","\n","        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n","\n","\n","        #誤差\n","        loss = functions.mean_squared_error(dd, y[:,t])\n","        \n","        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n","        \n","        all_loss += loss\n","\n","        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n","    \n","    \n","    for t in range(binary_dim)[::-1]:\n","        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n","\n","        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n","\n","        # 勾配更新\n","        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n","        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n","        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n","    \n","    # 勾配適用\n","    W_in -= learning_rate * W_in_grad\n","    W_out -= learning_rate * W_out_grad\n","    W -= learning_rate * W_grad\n","    \n","    W_in_grad *= 0\n","    W_out_grad *= 0\n","    W_grad *= 0\n","    \n","\n","    if(i % plot_interval == 0):\n","        all_losses.append(all_loss)        \n","        print(\"iters:\" + str(i))\n","        print(\"Loss:\" + str(all_loss))\n","        print(\"Pred:\" + str(out_bin))\n","        print(\"True:\" + str(d_bin))\n","        out_int = 0\n","        for index,x in enumerate(reversed(out_bin)):\n","            out_int += x * pow(2, index)\n","        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n","        print(\"------------\")\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, all_losses, label=\"loss\")\n","plt.show()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["iters:0\n","Loss:1.3690332060825618\n","Pred:[0 0 0 0 0 0 0 1]\n","True:[0 1 0 1 1 0 1 0]\n","50 + 40 = 1\n","------------\n","iters:100\n","Loss:1.0850196595517736\n","Pred:[0 0 0 0 0 0 1 0]\n","True:[1 0 1 1 0 0 0 0]\n","121 + 55 = 2\n","------------\n","iters:200\n","Loss:1.046010508731702\n","Pred:[1 1 1 1 1 1 1 1]\n","True:[0 1 1 1 0 0 1 0]\n","75 + 39 = 255\n","------------\n","iters:300\n","Loss:0.950064561421577\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 0 0 1 1]\n","95 + 68 = 0\n","------------\n","iters:400\n","Loss:1.1089393822332871\n","Pred:[1 1 1 1 1 1 1 0]\n","True:[0 1 0 1 0 1 0 0]\n","65 + 19 = 254\n","------------\n","iters:500\n","Loss:0.8995969658686043\n","Pred:[1 0 0 1 0 0 1 1]\n","True:[1 1 0 0 0 1 1 1]\n","88 + 111 = 147\n","------------\n","iters:600\n","Loss:0.9742204785457186\n","Pred:[0 1 0 0 0 0 1 1]\n","True:[0 1 0 1 1 0 0 1]\n","67 + 22 = 67\n","------------\n","iters:700\n","Loss:0.9715923589294146\n","Pred:[1 0 1 1 0 0 1 1]\n","True:[0 0 1 1 1 1 1 1]\n","19 + 44 = 179\n","------------\n","iters:800\n","Loss:1.1500975109197595\n","Pred:[1 1 1 1 1 1 1 0]\n","True:[1 0 0 0 1 1 0 0]\n","95 + 45 = 254\n","------------\n","iters:900\n","Loss:0.8841582537468087\n","Pred:[1 1 0 1 1 1 1 1]\n","True:[1 1 0 1 1 1 1 0]\n","110 + 112 = 223\n","------------\n","iters:1000\n","Loss:1.020769934018127\n","Pred:[0 0 0 1 0 1 0 0]\n","True:[0 0 1 1 1 0 1 0]\n","43 + 15 = 20\n","------------\n","iters:1100\n","Loss:0.9748083786585098\n","Pred:[0 0 0 0 0 0 0 1]\n","True:[1 0 0 0 1 0 0 0]\n","78 + 58 = 1\n","------------\n","iters:1200\n","Loss:0.8920972661119773\n","Pred:[0 0 0 0 0 0 1 1]\n","True:[0 0 0 1 1 0 1 0]\n","12 + 14 = 3\n","------------\n","iters:1300\n","Loss:0.9476964203533991\n","Pred:[0 0 0 0 0 1 0 1]\n","True:[1 0 0 1 1 1 0 1]\n","30 + 127 = 5\n","------------\n","iters:1400\n","Loss:1.1807751994496243\n","Pred:[0 1 1 0 1 0 1 0]\n","True:[1 0 0 1 0 1 0 0]\n","53 + 95 = 106\n","------------\n","iters:1500\n","Loss:1.0887149216513363\n","Pred:[0 1 0 1 0 1 0 0]\n","True:[0 1 1 0 1 0 1 0]\n","31 + 75 = 84\n","------------\n","iters:1600\n","Loss:0.9216405876921998\n","Pred:[1 1 1 1 0 1 0 1]\n","True:[0 1 0 1 0 1 0 1]\n","26 + 59 = 245\n","------------\n","iters:1700\n","Loss:0.8523968229538144\n","Pred:[1 0 0 1 0 0 0 1]\n","True:[1 1 0 1 1 0 0 1]\n","109 + 108 = 145\n","------------\n","iters:1800\n","Loss:0.9642153812760442\n","Pred:[0 1 0 1 1 0 0 1]\n","True:[1 0 0 1 1 0 1 1]\n","105 + 50 = 89\n","------------\n","iters:1900\n","Loss:0.6790008978816793\n","Pred:[1 0 1 0 1 0 0 1]\n","True:[1 0 1 0 1 0 0 1]\n","81 + 88 = 169\n","------------\n","iters:2000\n","Loss:0.7213622304808126\n","Pred:[0 1 1 1 1 0 1 1]\n","True:[0 1 1 1 1 1 1 1]\n","91 + 36 = 123\n","------------\n","iters:2100\n","Loss:0.640928486964822\n","Pred:[0 0 1 1 1 1 1 0]\n","True:[0 0 1 1 1 1 0 0]\n","29 + 31 = 62\n","------------\n","iters:2200\n","Loss:0.7183766484518945\n","Pred:[1 1 0 1 1 1 1 0]\n","True:[1 1 0 1 1 1 1 0]\n","109 + 113 = 222\n","------------\n","iters:2300\n","Loss:0.778693412131981\n","Pred:[0 0 0 1 1 0 0 0]\n","True:[0 0 0 1 1 1 1 0]\n","2 + 28 = 24\n","------------\n","iters:2400\n","Loss:0.9474258086203309\n","Pred:[0 0 1 0 1 0 1 0]\n","True:[0 1 1 1 0 0 0 0]\n","91 + 21 = 42\n","------------\n","iters:2500\n","Loss:1.0237690295311532\n","Pred:[1 0 0 1 1 1 1 0]\n","True:[1 0 1 0 0 0 0 0]\n","65 + 95 = 158\n","------------\n","iters:2600\n","Loss:0.45245289383589093\n","Pred:[0 1 0 1 1 1 1 1]\n","True:[0 1 0 1 0 1 1 1]\n","70 + 17 = 95\n","------------\n","iters:2700\n","Loss:1.0402887781256867\n","Pred:[1 1 0 1 1 1 1 0]\n","True:[1 1 1 0 0 0 1 0]\n","103 + 123 = 222\n","------------\n","iters:2800\n","Loss:0.40531748235998466\n","Pred:[0 0 1 1 1 1 0 1]\n","True:[0 0 1 1 1 1 0 1]\n","10 + 51 = 61\n","------------\n","iters:2900\n","Loss:0.7907722973963678\n","Pred:[0 1 0 0 1 0 1 1]\n","True:[0 1 1 1 1 1 1 1]\n","27 + 100 = 75\n","------------\n","iters:3000\n","Loss:0.39226996200026126\n","Pred:[0 1 1 0 1 0 0 1]\n","True:[0 1 1 0 1 0 0 1]\n","74 + 31 = 105\n","------------\n","iters:3100\n","Loss:0.41841391563584784\n","Pred:[1 1 0 0 0 0 0 1]\n","True:[1 1 1 0 0 0 0 1]\n","104 + 121 = 193\n","------------\n","iters:3200\n","Loss:0.5102354185950572\n","Pred:[1 1 0 1 0 0 1 1]\n","True:[1 0 0 1 0 0 1 1]\n","45 + 102 = 211\n","------------\n","iters:3300\n","Loss:0.6572059039340432\n","Pred:[0 1 1 0 1 1 0 0]\n","True:[0 1 0 0 1 0 0 0]\n","9 + 63 = 108\n","------------\n","iters:3400\n","Loss:0.13521258290670632\n","Pred:[1 0 1 0 1 1 0 0]\n","True:[1 0 1 0 1 1 0 0]\n","61 + 111 = 172\n","------------\n","iters:3500\n","Loss:0.13426243293400458\n","Pred:[0 1 1 0 1 0 0 1]\n","True:[0 1 1 0 1 0 0 1]\n","6 + 99 = 105\n","------------\n","iters:3600\n","Loss:0.1201137314045119\n","Pred:[0 1 1 1 1 0 0 1]\n","True:[0 1 1 1 1 0 0 1]\n","54 + 67 = 121\n","------------\n","iters:3700\n","Loss:0.36284395999419805\n","Pred:[1 0 0 0 1 1 1 1]\n","True:[1 0 0 0 1 1 1 1]\n","16 + 127 = 143\n","------------\n","iters:3800\n","Loss:0.10673902270527467\n","Pred:[1 0 1 0 1 1 1 0]\n","True:[1 0 1 0 1 1 1 0]\n","100 + 74 = 174\n","------------\n","iters:3900\n","Loss:0.16010386637444537\n","Pred:[0 1 1 1 1 0 0 0]\n","True:[0 1 1 1 1 0 0 0]\n","81 + 39 = 120\n","------------\n","iters:4000\n","Loss:0.15682998226964745\n","Pred:[0 1 0 1 1 0 0 0]\n","True:[0 1 0 1 1 0 0 0]\n","6 + 82 = 88\n","------------\n","iters:4100\n","Loss:0.03375574149134559\n","Pred:[0 1 1 0 1 0 0 0]\n","True:[0 1 1 0 1 0 0 0]\n","45 + 59 = 104\n","------------\n","iters:4200\n","Loss:0.047655477544710195\n","Pred:[1 0 0 0 0 1 0 1]\n","True:[1 0 0 0 0 1 0 1]\n","87 + 46 = 133\n","------------\n","iters:4300\n","Loss:0.1018928902806575\n","Pred:[0 1 0 1 1 0 0 0]\n","True:[0 1 0 1 1 0 0 0]\n","18 + 70 = 88\n","------------\n","iters:4400\n","Loss:0.04987916844639365\n","Pred:[0 1 1 1 0 0 0 0]\n","True:[0 1 1 1 0 0 0 0]\n","105 + 7 = 112\n","------------\n","iters:4500\n","Loss:0.04025496342428229\n","Pred:[0 1 1 1 0 0 0 0]\n","True:[0 1 1 1 0 0 0 0]\n","101 + 11 = 112\n","------------\n","iters:4600\n","Loss:0.07144241451053633\n","Pred:[0 1 1 1 0 1 0 0]\n","True:[0 1 1 1 0 1 0 0]\n","90 + 26 = 116\n","------------\n","iters:4700\n","Loss:0.025676571359688656\n","Pred:[1 0 1 1 1 0 0 1]\n","True:[1 0 1 1 1 0 0 1]\n","96 + 89 = 185\n","------------\n","iters:4800\n","Loss:0.016127819174188724\n","Pred:[1 0 0 1 0 1 1 0]\n","True:[1 0 0 1 0 1 1 0]\n","63 + 87 = 150\n","------------\n","iters:4900\n","Loss:0.03338769684474504\n","Pred:[0 1 0 0 0 1 1 1]\n","True:[0 1 0 0 0 1 1 1]\n","68 + 3 = 71\n","------------\n","iters:5000\n","Loss:0.022215208244751126\n","Pred:[0 1 1 1 1 1 1 1]\n","True:[0 1 1 1 1 1 1 1]\n","64 + 63 = 127\n","------------\n","iters:5100\n","Loss:0.022302421461422754\n","Pred:[1 0 1 0 0 0 0 1]\n","True:[1 0 1 0 0 0 0 1]\n","82 + 79 = 161\n","------------\n","iters:5200\n","Loss:0.01833991079176863\n","Pred:[0 0 1 0 1 1 0 1]\n","True:[0 0 1 0 1 1 0 1]\n","2 + 43 = 45\n","------------\n","iters:5300\n","Loss:0.014507751118479338\n","Pred:[0 1 1 0 0 0 1 1]\n","True:[0 1 1 0 0 0 1 1]\n","34 + 65 = 99\n","------------\n","iters:5400\n","Loss:0.04477010783782255\n","Pred:[0 1 1 0 0 0 0 0]\n","True:[0 1 1 0 0 0 0 0]\n","72 + 24 = 96\n","------------\n","iters:5500\n","Loss:0.013950224219501496\n","Pred:[1 0 0 0 1 1 1 1]\n","True:[1 0 0 0 1 1 1 1]\n","21 + 122 = 143\n","------------\n","iters:5600\n","Loss:0.01402516967605031\n","Pred:[1 1 0 0 0 1 0 1]\n","True:[1 1 0 0 0 1 0 1]\n","75 + 122 = 197\n","------------\n","iters:5700\n","Loss:0.02768156289653929\n","Pred:[0 0 1 1 1 0 1 0]\n","True:[0 0 1 1 1 0 1 0]\n","24 + 34 = 58\n","------------\n","iters:5800\n","Loss:0.01037829062337891\n","Pred:[1 0 0 1 1 0 0 1]\n","True:[1 0 0 1 1 0 0 1]\n","101 + 52 = 153\n","------------\n","iters:5900\n","Loss:0.002303744420090667\n","Pred:[0 1 0 1 1 1 1 0]\n","True:[0 1 0 1 1 1 1 0]\n","51 + 43 = 94\n","------------\n","iters:6000\n","Loss:0.009565938650474625\n","Pred:[1 0 0 1 0 1 0 1]\n","True:[1 0 0 1 0 1 0 1]\n","114 + 35 = 149\n","------------\n","iters:6100\n","Loss:0.008913333927197778\n","Pred:[0 1 1 0 0 1 1 1]\n","True:[0 1 1 0 0 1 1 1]\n","2 + 101 = 103\n","------------\n","iters:6200\n","Loss:0.010069858501089447\n","Pred:[1 0 0 1 1 0 0 1]\n","True:[1 0 0 1 1 0 0 1]\n","99 + 54 = 153\n","------------\n","iters:6300\n","Loss:0.013641574435422573\n","Pred:[1 0 0 1 0 0 0 1]\n","True:[1 0 0 1 0 0 0 1]\n","52 + 93 = 145\n","------------\n","iters:6400\n","Loss:0.0025277822726405942\n","Pred:[1 0 1 1 1 1 1 0]\n","True:[1 0 1 1 1 1 1 0]\n","101 + 89 = 190\n","------------\n","iters:6500\n","Loss:0.01019959071301772\n","Pred:[1 1 0 0 0 0 1 1]\n","True:[1 1 0 0 0 0 1 1]\n","94 + 101 = 195\n","------------\n","iters:6600\n","Loss:0.01070642752976012\n","Pred:[1 0 0 1 0 0 0 1]\n","True:[1 0 0 1 0 0 0 1]\n","18 + 127 = 145\n","------------\n","iters:6700\n","Loss:0.0038340398805109224\n","Pred:[1 0 0 0 0 0 0 0]\n","True:[1 0 0 0 0 0 0 0]\n","65 + 63 = 128\n","------------\n","iters:6800\n","Loss:0.017351843405165653\n","Pred:[1 1 0 1 1 1 1 0]\n","True:[1 1 0 1 1 1 1 0]\n","112 + 110 = 222\n","------------\n","iters:6900\n","Loss:0.0014734817165044218\n","Pred:[0 1 1 1 1 1 1 0]\n","True:[0 1 1 1 1 1 1 0]\n","45 + 81 = 126\n","------------\n","iters:7000\n","Loss:0.002034287992632181\n","Pred:[0 1 1 0 1 1 0 0]\n","True:[0 1 1 0 1 1 0 0]\n","27 + 81 = 108\n","------------\n","iters:7100\n","Loss:0.007791413857129424\n","Pred:[0 0 1 0 1 0 1 1]\n","True:[0 0 1 0 1 0 1 1]\n","8 + 35 = 43\n","------------\n","iters:7200\n","Loss:0.013034505424126559\n","Pred:[0 1 1 1 1 1 0 0]\n","True:[0 1 1 1 1 1 0 0]\n","76 + 48 = 124\n","------------\n","iters:7300\n","Loss:0.004976437985146758\n","Pred:[1 0 1 1 1 1 0 1]\n","True:[1 0 1 1 1 1 0 1]\n","64 + 125 = 189\n","------------\n","iters:7400\n","Loss:0.0020214984943279926\n","Pred:[0 1 1 1 0 1 0 0]\n","True:[0 1 1 1 0 1 0 0]\n","73 + 43 = 116\n","------------\n","iters:7500\n","Loss:0.0007158119217197717\n","Pred:[1 0 1 0 1 0 0 0]\n","True:[1 0 1 0 1 0 0 0]\n","127 + 41 = 168\n","------------\n","iters:7600\n","Loss:0.001546991743798971\n","Pred:[0 1 1 1 1 0 0 0]\n","True:[0 1 1 1 1 0 0 0]\n","35 + 85 = 120\n","------------\n","iters:7700\n","Loss:0.011145745576411204\n","Pred:[1 0 1 0 0 1 0 0]\n","True:[1 0 1 0 0 1 0 0]\n","118 + 46 = 164\n","------------\n","iters:7800\n","Loss:0.011252289782368582\n","Pred:[0 1 1 0 0 0 1 0]\n","True:[0 1 1 0 0 0 1 0]\n","94 + 4 = 98\n","------------\n","iters:7900\n","Loss:0.003164119167063139\n","Pred:[0 1 1 1 0 1 0 1]\n","True:[0 1 1 1 0 1 0 1]\n","15 + 102 = 117\n","------------\n","iters:8000\n","Loss:0.004210994199089458\n","Pred:[1 0 1 0 0 0 0 1]\n","True:[1 0 1 0 0 0 0 1]\n","35 + 126 = 161\n","------------\n","iters:8100\n","Loss:0.0009296696647847518\n","Pred:[0 1 1 1 1 1 1 0]\n","True:[0 1 1 1 1 1 1 0]\n","97 + 29 = 126\n","------------\n","iters:8200\n","Loss:0.003755158247523374\n","Pred:[0 1 0 0 1 0 0 1]\n","True:[0 1 0 0 1 0 0 1]\n","52 + 21 = 73\n","------------\n","iters:8300\n","Loss:0.0009070301192823051\n","Pred:[1 1 1 1 0 0 1 0]\n","True:[1 1 1 1 0 0 1 0]\n","115 + 127 = 242\n","------------\n","iters:8400\n","Loss:0.004836049223117474\n","Pred:[1 0 0 0 1 0 1 1]\n","True:[1 0 0 0 1 0 1 1]\n","126 + 13 = 139\n","------------\n","iters:8500\n","Loss:0.008150407035658336\n","Pred:[1 0 1 1 1 1 1 0]\n","True:[1 0 1 1 1 1 1 0]\n","98 + 92 = 190\n","------------\n","iters:8600\n","Loss:0.004119382308530085\n","Pred:[1 0 0 1 0 1 1 1]\n","True:[1 0 0 1 0 1 1 1]\n","106 + 45 = 151\n","------------\n","iters:8700\n","Loss:0.0035448243107715324\n","Pred:[1 0 1 1 1 0 0 1]\n","True:[1 0 1 1 1 0 0 1]\n","110 + 75 = 185\n","------------\n","iters:8800\n","Loss:0.0041672499114343365\n","Pred:[1 0 0 1 0 0 0 1]\n","True:[1 0 0 1 0 0 0 1]\n","114 + 31 = 145\n","------------\n","iters:8900\n","Loss:0.007090395313543606\n","Pred:[0 1 0 1 1 1 0 0]\n","True:[0 1 0 1 1 1 0 0]\n","8 + 84 = 92\n","------------\n","iters:9000\n","Loss:0.0019714404461368754\n","Pred:[1 1 0 1 1 1 1 1]\n","True:[1 1 0 1 1 1 1 1]\n","105 + 118 = 223\n","------------\n","iters:9100\n","Loss:0.0017934615186568322\n","Pred:[0 1 1 1 0 0 0 1]\n","True:[0 1 1 1 0 0 0 1]\n","87 + 26 = 113\n","------------\n","iters:9200\n","Loss:0.0022907924740614137\n","Pred:[1 0 0 1 1 0 0 1]\n","True:[1 0 0 1 1 0 0 1]\n","29 + 124 = 153\n","------------\n","iters:9300\n","Loss:0.0030500024846643716\n","Pred:[0 1 0 0 1 0 1 1]\n","True:[0 1 0 0 1 0 1 1]\n","18 + 57 = 75\n","------------\n","iters:9400\n","Loss:0.0016513381291542218\n","Pred:[0 1 0 0 0 0 1 1]\n","True:[0 1 0 0 0 0 1 1]\n","49 + 18 = 67\n","------------\n","iters:9500\n","Loss:0.005899086937737134\n","Pred:[0 1 1 1 0 0 1 0]\n","True:[0 1 1 1 0 0 1 0]\n","18 + 96 = 114\n","------------\n","iters:9600\n","Loss:0.0028884132024246975\n","Pred:[1 0 1 0 0 0 1 1]\n","True:[1 0 1 0 0 0 1 1]\n","84 + 79 = 163\n","------------\n","iters:9700\n","Loss:0.0013591802505521972\n","Pred:[1 0 0 1 0 0 0 1]\n","True:[1 0 0 1 0 0 0 1]\n","73 + 72 = 145\n","------------\n","iters:9800\n","Loss:0.0015111455297025117\n","Pred:[0 1 0 1 0 1 0 1]\n","True:[0 1 0 1 0 1 0 1]\n","43 + 42 = 85\n","------------\n","iters:9900\n","Loss:0.004925421189122537\n","Pred:[0 1 1 0 1 1 0 0]\n","True:[0 1 1 0 1 1 0 0]\n","92 + 16 = 108\n","------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"O7zQEPrtP4OP"},"source":["---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n","\n","\n","## [try] 重みの初期化方法を変更してみよう\n","Xavier, He\n","\n","## [try] 中間層の活性化関数を変更してみよう\n","ReLU(勾配爆発を確認しよう)<br>\n","tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)\n","\n","---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"W3Mbb5akfJoi"},"source":["ReLU(勾配爆発を確認する)"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Wxn1AKKMehRu","executionInfo":{"status":"ok","timestamp":1626408984553,"user_tz":-540,"elapsed":9954,"user":{"displayName":"横路岳彦","photoUrl":"","userId":"02779192865702045545"}},"outputId":"06ee9496-6ed9-44c9-9424-42a1a72277c9"},"source":["import numpy as np\n","from common import functions\n","import matplotlib.pyplot as plt\n","\n","# def d_tanh(x):\n","\n","\n","\n","# データを用意\n","# 2進数の桁数\n","binary_dim = 8\n","# 最大値 + 1\n","largest_number = pow(2, binary_dim)\n","# largest_numberまで2進数を用意\n","binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n","\n","input_layer_size = 2\n","hidden_layer_size = 16\n","output_layer_size = 1\n","\n","weight_init_std = 1\n","learning_rate = 0.1\n","\n","iters_num = 10000\n","plot_interval = 100\n","\n","# ウェイト初期化 (バイアスは簡単のため省略)\n","W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n","W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n","W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n","\n","# Xavier\n","\n","\n","# He\n","\n","\n","\n","# 勾配\n","W_in_grad = np.zeros_like(W_in)\n","W_out_grad = np.zeros_like(W_out)\n","W_grad = np.zeros_like(W)\n","\n","u = np.zeros((hidden_layer_size, binary_dim + 1))\n","z = np.zeros((hidden_layer_size, binary_dim + 1))\n","y = np.zeros((output_layer_size, binary_dim))\n","\n","delta_out = np.zeros((output_layer_size, binary_dim))\n","delta = np.zeros((hidden_layer_size, binary_dim + 1))\n","\n","all_losses = []\n","\n","for i in range(iters_num):\n","    \n","    # A, B初期化 (a + b = d)\n","    a_int = np.random.randint(largest_number/2)\n","    a_bin = binary[a_int] # binary encoding\n","    b_int = np.random.randint(largest_number/2)\n","    b_bin = binary[b_int] # binary encoding\n","    \n","    # 正解データ\n","    d_int = a_int + b_int\n","    d_bin = binary[d_int]\n","    \n","    # 出力バイナリ\n","    out_bin = np.zeros_like(d_bin)\n","    \n","    # 時系列全体の誤差\n","    all_loss = 0    \n","    \n","    # 時系列ループ\n","    for t in range(binary_dim):\n","        # 入力値\n","        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n","        # 時刻tにおける正解データ\n","        dd = np.array([d_bin[binary_dim - t - 1]])\n","        \n","        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n","        z[:,t+1] = functions.relu(u[:,t+1])\n","\n","        y[:,t] = functions.relu(np.dot(z[:,t+1].reshape(1, -1), W_out))\n","\n","\n","        #誤差\n","        loss = functions.mean_squared_error(dd, y[:,t])\n","        \n","        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_relu(y[:,t])        \n","        \n","        all_loss += loss\n","\n","        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n","    \n","    \n","    for t in range(binary_dim)[::-1]:\n","        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n","\n","        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n","\n","        # 勾配更新\n","        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n","        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n","        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n","    \n","    # 勾配適用\n","    W_in -= learning_rate * W_in_grad\n","    W_out -= learning_rate * W_out_grad\n","    W -= learning_rate * W_grad\n","    \n","    W_in_grad *= 0\n","    W_out_grad *= 0\n","    W_grad *= 0\n","    \n","\n","    if(i % plot_interval == 0):\n","        all_losses.append(all_loss)        \n","        print(\"iters:\" + str(i))\n","        print(\"Loss:\" + str(all_loss))\n","        print(\"Pred:\" + str(out_bin))\n","        print(\"True:\" + str(d_bin))\n","        out_int = 0\n","        for index,x in enumerate(reversed(out_bin)):\n","            out_int += x * pow(2, index)\n","        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n","        print(\"------------\")\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, all_losses, label=\"loss\")\n","plt.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["iters:0\n","Loss:7743893.29685929\n","Pred:[ 47 223 185  92  25  10   3   0]\n","True:[0 0 0 1 0 0 0 1]\n","11 + 6 = 27926\n","------------\n","iters:100\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 0 0 1 1 1]\n","105 + 126 = 0\n","------------\n","iters:200\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 0 0 0 0 1]\n","105 + 120 = 0\n","------------\n","iters:300\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 0 0 0]\n","121 + 63 = 0\n","------------\n","iters:400\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 0 0 0 1 0 1]\n","80 + 117 = 0\n","------------\n","iters:500\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 0 1 0 1 0]\n","94 + 12 = 0\n","------------\n","iters:600\n","Loss:3.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 1 1 1]\n","87 + 104 = 0\n","------------\n","iters:700\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 0 0 1 0]\n","59 + 119 = 0\n","------------\n","iters:800\n","Loss:0.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 0 0 0 0 0]\n","7 + 25 = 0\n","------------\n","iters:900\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 1 0 1 0]\n","39 + 35 = 0\n","------------\n","iters:1000\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 0 0 1 0]\n","4 + 110 = 0\n","------------\n","iters:1100\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 0 1 1 0]\n","46 + 120 = 0\n","------------\n","iters:1200\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 0 1 0 0]\n","93 + 23 = 0\n","------------\n","iters:1300\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 1 0 1 0 1]\n","119 + 126 = 0\n","------------\n","iters:1400\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 0 0 0 1]\n","91 + 86 = 0\n","------------\n","iters:1500\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 0 0 0 0 0 0]\n","125 + 67 = 0\n","------------\n","iters:1600\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 1 0 1 1]\n","108 + 47 = 0\n","------------\n","iters:1700\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 0 1 1 1 1]\n","6 + 41 = 0\n","------------\n","iters:1800\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 0 0 1 0 1]\n","124 + 105 = 0\n","------------\n","iters:1900\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 1 1 0 0]\n","34 + 42 = 0\n","------------\n","iters:2000\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 0 1 0 1]\n","119 + 30 = 0\n","------------\n","iters:2100\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 0 1 0 0]\n","108 + 24 = 0\n","------------\n","iters:2200\n","Loss:3.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 1 1 1]\n","109 + 82 = 0\n","------------\n","iters:2300\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 1 1 1]\n","0 + 95 = 0\n","------------\n","iters:2400\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 0 1 1 0 0]\n","116 + 120 = 0\n","------------\n","iters:2500\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 0 0 1 0]\n","26 + 40 = 0\n","------------\n","iters:2600\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 0 1 1 1]\n","107 + 60 = 0\n","------------\n","iters:2700\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 0 1 1 0 0]\n","67 + 41 = 0\n","------------\n","iters:2800\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 1 1 0 0]\n","49 + 123 = 0\n","------------\n","iters:2900\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 0 0 0 1]\n","99 + 30 = 0\n","------------\n","iters:3000\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 1 0 1 0]\n","84 + 54 = 0\n","------------\n","iters:3100\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 0 0 1 1 1]\n","22 + 17 = 0\n","------------\n","iters:3200\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 0 1 1]\n","54 + 37 = 0\n","------------\n","iters:3300\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 0 1 0 1]\n","46 + 39 = 0\n","------------\n","iters:3400\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 1 1 1 0]\n","41 + 85 = 0\n","------------\n","iters:3500\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 0 0 0 1]\n","75 + 86 = 0\n","------------\n","iters:3600\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 0 0 1 1]\n","54 + 77 = 0\n","------------\n","iters:3700\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 0 0 1 1 1]\n","63 + 40 = 0\n","------------\n","iters:3800\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 0 0 0 0 1]\n","125 + 100 = 0\n","------------\n","iters:3900\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 1 0 1 0]\n","11 + 127 = 0\n","------------\n","iters:4000\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 1 0 0 1]\n","20 + 101 = 0\n","------------\n","iters:4100\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 1 0 1 1]\n","55 + 20 = 0\n","------------\n","iters:4200\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 0 0 1 0]\n","34 + 48 = 0\n","------------\n","iters:4300\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 1 0 0 1]\n","58 + 79 = 0\n","------------\n","iters:4400\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 0 0 1 0 1]\n","48 + 53 = 0\n","------------\n","iters:4500\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 1 0 0 0 1]\n","32 + 17 = 0\n","------------\n","iters:4600\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 0 0 1 1]\n","47 + 36 = 0\n","------------\n","iters:4700\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 0 0 1 0]\n","35 + 31 = 0\n","------------\n","iters:4800\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 1 1 1 0 0]\n","8 + 52 = 0\n","------------\n","iters:4900\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 0 0 1 0 0]\n","90 + 10 = 0\n","------------\n","iters:5000\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 0 0 0 1]\n","30 + 51 = 0\n","------------\n","iters:5100\n","Loss:0.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 0 0 0 0]\n","46 + 82 = 0\n","------------\n","iters:5200\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 0 0 1 0 0]\n","23 + 13 = 0\n","------------\n","iters:5300\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 1 1 1 1]\n","124 + 35 = 0\n","------------\n","iters:5400\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 0 1 0 1]\n","6 + 63 = 0\n","------------\n","iters:5500\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 1 1 1 1]\n","51 + 108 = 0\n","------------\n","iters:5600\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 1 0 1 0]\n","115 + 39 = 0\n","------------\n","iters:5700\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 0 0 1 0]\n","19 + 127 = 0\n","------------\n","iters:5800\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 1 0 1]\n","81 + 12 = 0\n","------------\n","iters:5900\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 1 1 0]\n","82 + 108 = 0\n","------------\n","iters:6000\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 1 1 0]\n","2 + 92 = 0\n","------------\n","iters:6100\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 0 0 1 0]\n","7 + 123 = 0\n","------------\n","iters:6200\n","Loss:3.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 1 1 1]\n","107 + 84 = 0\n","------------\n","iters:6300\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 1 1 0 1]\n","34 + 43 = 0\n","------------\n","iters:6400\n","Loss:3.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 1 1 1 1]\n","76 + 51 = 0\n","------------\n","iters:6500\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 0 1 1]\n","46 + 45 = 0\n","------------\n","iters:6600\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 0 1 0]\n","109 + 77 = 0\n","------------\n","iters:6700\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 0 0 1 0 0]\n","74 + 26 = 0\n","------------\n","iters:6800\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 0 0 0 0]\n","122 + 22 = 0\n","------------\n","iters:6900\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 1 0 1 1]\n","24 + 99 = 0\n","------------\n","iters:7000\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 0 1 1 1]\n","50 + 21 = 0\n","------------\n","iters:7100\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 0 1 0 0]\n","53 + 31 = 0\n","------------\n","iters:7200\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 1 0 1 0 0]\n","119 + 125 = 0\n","------------\n","iters:7300\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 0 1 1 1 0]\n","17 + 29 = 0\n","------------\n","iters:7400\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 0 1 1 1 1 1]\n","24 + 7 = 0\n","------------\n","iters:7500\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 0 0 1]\n","84 + 101 = 0\n","------------\n","iters:7600\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 0 0 0 1 1]\n","23 + 12 = 0\n","------------\n","iters:7700\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 0 1 0 0]\n","103 + 13 = 0\n","------------\n","iters:7800\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 0 0 0 0 1 1]\n","110 + 85 = 0\n","------------\n","iters:7900\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 0 1 1 0]\n","58 + 92 = 0\n","------------\n","iters:8000\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 0 1 1 0 0 1 1]\n","50 + 1 = 0\n","------------\n","iters:8100\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 0 1 0 1]\n","55 + 94 = 0\n","------------\n","iters:8200\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 1 1 0 1]\n","78 + 95 = 0\n","------------\n","iters:8300\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 0 0 1 1]\n","39 + 28 = 0\n","------------\n","iters:8400\n","Loss:3.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 0 1 1 1 1 1]\n","98 + 125 = 0\n","------------\n","iters:8500\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 1 1 1 0 1]\n","101 + 56 = 0\n","------------\n","iters:8600\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 0 1 1 1]\n","82 + 5 = 0\n","------------\n","iters:8700\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 0 1 0 1 1]\n","74 + 1 = 0\n","------------\n","iters:8800\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 0 0 1 0 1 0]\n","119 + 19 = 0\n","------------\n","iters:8900\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 0 1 0 1]\n","93 + 88 = 0\n","------------\n","iters:9000\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 0 0 1 1 1 0]\n","121 + 85 = 0\n","------------\n","iters:9100\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 1 1 0 0]\n","73 + 51 = 0\n","------------\n","iters:9200\n","Loss:2.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 1 1 0 0 1 0 0]\n","111 + 117 = 0\n","------------\n","iters:9300\n","Loss:1.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 0 0 0 1]\n","37 + 124 = 0\n","------------\n","iters:9400\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 1 1 0]\n","88 + 6 = 0\n","------------\n","iters:9500\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 0 1 1 1 1 0]\n","80 + 14 = 0\n","------------\n","iters:9600\n","Loss:2.5\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[0 1 1 1 0 0 1 1]\n","102 + 13 = 0\n","------------\n","iters:9700\n","Loss:1.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 0 0 0 0]\n","33 + 127 = 0\n","------------\n","iters:9800\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 1 1 0 1 1]\n","116 + 71 = 0\n","------------\n","iters:9900\n","Loss:3.0\n","Pred:[0 0 0 0 0 0 0 0]\n","True:[1 0 1 0 1 1 1 1]\n","102 + 73 = 0\n","------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"S7rX6viEjDvT"},"source":["中間層の活性化関数をtanhに変更、また\n","Xavier初期化を行う。\n"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0DfyhZmthGtW","executionInfo":{"status":"ok","timestamp":1626409639122,"user_tz":-540,"elapsed":9695,"user":{"displayName":"横路岳彦","photoUrl":"","userId":"02779192865702045545"}},"outputId":"ed836682-5214-4fa6-e03f-498499a6b12d"},"source":["import numpy as np\n","from common import functions\n","import matplotlib.pyplot as plt\n","\n","def d_tanh(x):\n","    return 1/(np.cosh(x) ** 2)\n","\n","\n","# データを用意\n","# 2進数の桁数\n","binary_dim = 8\n","# 最大値 + 1\n","largest_number = pow(2, binary_dim)\n","# largest_numberまで2進数を用意\n","binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n","\n","input_layer_size = 2\n","hidden_layer_size = 16\n","output_layer_size = 1\n","\n","weight_init_std = 1\n","learning_rate = 0.1\n","\n","iters_num = 10000\n","plot_interval = 100\n","\n","# ウェイト初期化 (バイアスは簡単のため省略)\n","#W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n","#W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n","#W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n","\n","# Xavier\n","W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n","W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n","W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n","\n","# He\n","\n","\n","\n","# 勾配\n","W_in_grad = np.zeros_like(W_in)\n","W_out_grad = np.zeros_like(W_out)\n","W_grad = np.zeros_like(W)\n","\n","u = np.zeros((hidden_layer_size, binary_dim + 1))\n","z = np.zeros((hidden_layer_size, binary_dim + 1))\n","y = np.zeros((output_layer_size, binary_dim))\n","\n","delta_out = np.zeros((output_layer_size, binary_dim))\n","delta = np.zeros((hidden_layer_size, binary_dim + 1))\n","\n","all_losses = []\n","\n","for i in range(iters_num):\n","    \n","    # A, B初期化 (a + b = d)\n","    a_int = np.random.randint(largest_number/2)\n","    a_bin = binary[a_int] # binary encoding\n","    b_int = np.random.randint(largest_number/2)\n","    b_bin = binary[b_int] # binary encoding\n","    \n","    # 正解データ\n","    d_int = a_int + b_int\n","    d_bin = binary[d_int]\n","    \n","    # 出力バイナリ\n","    out_bin = np.zeros_like(d_bin)\n","    \n","    # 時系列全体の誤差\n","    all_loss = 0    \n","    \n","    # 時系列ループ\n","    for t in range(binary_dim):\n","        # 入力値\n","        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n","        # 時刻tにおける正解データ\n","        dd = np.array([d_bin[binary_dim - t - 1]])\n","        \n","        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n","        z[:,t+1] = np.tanh(u[:,t+1])\n","\n","        y[:,t] = np.tanh(np.dot(z[:,t+1].reshape(1, -1), W_out))\n","\n","\n","        #誤差\n","        loss = functions.mean_squared_error(dd, y[:,t])\n","        \n","        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * d_tanh(y[:,t])        \n","        \n","        all_loss += loss\n","\n","        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n","    \n","    \n","    for t in range(binary_dim)[::-1]:\n","        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n","\n","        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])\n","\n","        # 勾配更新\n","        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n","        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n","        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n","    \n","    # 勾配適用\n","    W_in -= learning_rate * W_in_grad\n","    W_out -= learning_rate * W_out_grad\n","    W -= learning_rate * W_grad\n","    \n","    W_in_grad *= 0\n","    W_out_grad *= 0\n","    W_grad *= 0\n","    \n","\n","    if(i % plot_interval == 0):\n","        all_losses.append(all_loss)        \n","        print(\"iters:\" + str(i))\n","        print(\"Loss:\" + str(all_loss))\n","        print(\"Pred:\" + str(out_bin))\n","        print(\"True:\" + str(d_bin))\n","        out_int = 0\n","        for index,x in enumerate(reversed(out_bin)):\n","            out_int += x * pow(2, index)\n","        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n","        print(\"------------\")\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, all_losses, label=\"loss\")\n","plt.show()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["iters:0\n","Loss:6.672118794657662\n","Pred:[  0   0 255 255 255 255   0   0]\n","True:[0 0 1 1 1 1 1 0]\n","61 + 1 = 15300\n","------------\n","iters:100\n","Loss:0.5263051835389605\n","Pred:[1 1 1 1 1 1 1 0]\n","True:[1 0 1 1 1 1 1 0]\n","74 + 116 = 254\n","------------\n","iters:200\n","Loss:0.43827838121624296\n","Pred:[0 1 1 1 1 1 1 1]\n","True:[0 1 1 1 1 1 0 1]\n","114 + 11 = 127\n","------------\n","iters:300\n","Loss:0.5951366390937869\n","Pred:[1 1 0 1 1 0 1 0]\n","True:[1 0 0 1 0 0 1 0]\n","29 + 117 = 218\n","------------\n","iters:400\n","Loss:0.1789732123823188\n","Pred:[0 1 1 0 0 1 0 0]\n","True:[0 1 1 0 0 1 0 0]\n","45 + 55 = 100\n","------------\n","iters:500\n","Loss:0.13934237716368394\n","Pred:[1 1 0 0 1 1 0 0]\n","True:[1 1 0 0 1 1 0 0]\n","82 + 122 = 204\n","------------\n","iters:600\n","Loss:0.0780932036066283\n","Pred:[1 0 0 0 0 0 1 0]\n","True:[1 0 0 0 0 0 1 0]\n","127 + 3 = 130\n","------------\n","iters:700\n","Loss:0.27073324213993966\n","Pred:[0 0 1 0 1 0 0 1]\n","True:[0 0 1 0 1 0 0 1]\n","37 + 4 = 41\n","------------\n","iters:800\n","Loss:0.12065609064685916\n","Pred:[0 1 0 0 1 1 0 0]\n","True:[0 1 0 0 1 1 0 0]\n","66 + 10 = 76\n","------------\n","iters:900\n","Loss:0.07205480178683349\n","Pred:[1 0 1 0 0 1 0 0]\n","True:[1 0 1 0 0 1 0 0]\n","49 + 115 = 164\n","------------\n","iters:1000\n","Loss:0.005154846389377532\n","Pred:[0 1 1 0 1 1 1 1]\n","True:[0 1 1 0 1 1 1 1]\n","101 + 10 = 111\n","------------\n","iters:1100\n","Loss:0.03699824520354692\n","Pred:[0 1 0 1 0 1 1 1]\n","True:[0 1 0 1 0 1 1 1]\n","34 + 53 = 87\n","------------\n","iters:1200\n","Loss:0.0064189331547102185\n","Pred:[0 1 0 1 0 0 0 0]\n","True:[0 1 0 1 0 0 0 0]\n","42 + 38 = 80\n","------------\n","iters:1300\n","Loss:0.04551163847482358\n","Pred:[1 0 1 0 0 0 0 1]\n","True:[1 0 1 0 0 0 0 1]\n","52 + 109 = 161\n","------------\n","iters:1400\n","Loss:0.027107688632822362\n","Pred:[0 1 1 0 1 0 0 1]\n","True:[0 1 1 0 1 0 0 1]\n","67 + 38 = 105\n","------------\n","iters:1500\n","Loss:0.040783897971986977\n","Pred:[0 1 1 1 1 1 1 1]\n","True:[0 1 1 1 1 1 1 1]\n","30 + 97 = 127\n","------------\n","iters:1600\n","Loss:0.02137417577131865\n","Pred:[0 1 1 1 1 1 0 1]\n","True:[0 1 1 1 1 1 0 1]\n","16 + 109 = 125\n","------------\n","iters:1700\n","Loss:0.001422532606856712\n","Pred:[1 0 0 1 1 1 1 0]\n","True:[1 0 0 1 1 1 1 0]\n","46 + 112 = 158\n","------------\n","iters:1800\n","Loss:0.2563551442916463\n","Pred:[1 0 1 0 1 1 1 1]\n","True:[1 0 1 0 1 1 0 1]\n","95 + 78 = 175\n","------------\n","iters:1900\n","Loss:0.00327230676790699\n","Pred:[1 1 0 1 1 1 0 0]\n","True:[1 1 0 1 1 1 0 0]\n","114 + 106 = 220\n","------------\n","iters:2000\n","Loss:0.004488744931667281\n","Pred:[1 0 0 1 0 1 1 1]\n","True:[1 0 0 1 0 1 1 1]\n","123 + 28 = 151\n","------------\n","iters:2100\n","Loss:0.005874914009400333\n","Pred:[1 1 1 0 0 0 1 1]\n","True:[1 1 1 0 0 0 1 1]\n","122 + 105 = 227\n","------------\n","iters:2200\n","Loss:0.004370454554191954\n","Pred:[0 1 1 0 1 0 0 0]\n","True:[0 1 1 0 1 0 0 0]\n","76 + 28 = 104\n","------------\n","iters:2300\n","Loss:0.009212978442840329\n","Pred:[0 0 1 0 0 0 1 1]\n","True:[0 0 1 0 0 0 1 1]\n","30 + 5 = 35\n","------------\n","iters:2400\n","Loss:0.0002444318798376356\n","Pred:[0 1 0 0 1 0 0 0]\n","True:[0 1 0 0 1 0 0 0]\n","17 + 55 = 72\n","------------\n","iters:2500\n","Loss:0.02288097128255921\n","Pred:[1 0 0 1 0 0 1 0]\n","True:[1 0 0 1 0 0 1 0]\n","42 + 104 = 146\n","------------\n","iters:2600\n","Loss:0.001682669459216865\n","Pred:[0 1 0 1 1 0 0 1]\n","True:[0 1 0 1 1 0 0 1]\n","43 + 46 = 89\n","------------\n","iters:2700\n","Loss:0.005851574131382892\n","Pred:[1 1 0 0 0 0 1 0]\n","True:[1 1 0 0 0 0 1 0]\n","85 + 109 = 194\n","------------\n","iters:2800\n","Loss:0.0021916217775379385\n","Pred:[0 1 1 0 1 0 1 1]\n","True:[0 1 1 0 1 0 1 1]\n","10 + 97 = 107\n","------------\n","iters:2900\n","Loss:0.0010785528593714989\n","Pred:[0 1 1 0 0 1 0 1]\n","True:[0 1 1 0 0 1 0 1]\n","2 + 99 = 101\n","------------\n","iters:3000\n","Loss:0.003164027235632667\n","Pred:[0 0 1 0 0 0 0 0]\n","True:[0 0 1 0 0 0 0 0]\n","20 + 12 = 32\n","------------\n","iters:3100\n","Loss:0.003676595527309622\n","Pred:[0 1 0 1 0 1 0 1]\n","True:[0 1 0 1 0 1 0 1]\n","74 + 11 = 85\n","------------\n","iters:3200\n","Loss:0.0006830335524159463\n","Pred:[0 1 0 0 0 0 0 0]\n","True:[0 1 0 0 0 0 0 0]\n","55 + 9 = 64\n","------------\n","iters:3300\n","Loss:0.00106906520155104\n","Pred:[1 1 0 1 0 0 0 1]\n","True:[1 1 0 1 0 0 0 1]\n","127 + 82 = 209\n","------------\n","iters:3400\n","Loss:0.00024044390646776501\n","Pred:[1 0 1 1 1 1 1 0]\n","True:[1 0 1 1 1 1 1 0]\n","114 + 76 = 190\n","------------\n","iters:3500\n","Loss:0.003878720769407481\n","Pred:[0 1 0 1 1 0 0 1]\n","True:[0 1 0 1 1 0 0 1]\n","49 + 40 = 89\n","------------\n","iters:3600\n","Loss:0.001279063969166383\n","Pred:[1 0 1 1 0 1 1 1]\n","True:[1 0 1 1 0 1 1 1]\n","117 + 66 = 183\n","------------\n","iters:3700\n","Loss:0.0024757682945394815\n","Pred:[1 0 1 0 0 1 0 1]\n","True:[1 0 1 0 0 1 0 1]\n","61 + 104 = 165\n","------------\n","iters:3800\n","Loss:0.002578744396854978\n","Pred:[0 0 0 1 0 1 1 1]\n","True:[0 0 0 1 0 1 1 1]\n","17 + 6 = 23\n","------------\n","iters:3900\n","Loss:5.414982547870588e-05\n","Pred:[1 0 1 0 0 0 1 0]\n","True:[1 0 1 0 0 0 1 0]\n","43 + 119 = 162\n","------------\n","iters:4000\n","Loss:0.0017196542769130666\n","Pred:[1 0 1 0 1 0 0 1]\n","True:[1 0 1 0 1 0 0 1]\n","59 + 110 = 169\n","------------\n","iters:4100\n","Loss:0.01025141244442939\n","Pred:[0 0 1 0 1 0 1 1]\n","True:[0 0 1 0 1 0 1 1]\n","37 + 6 = 43\n","------------\n","iters:4200\n","Loss:0.007359515549269988\n","Pred:[0 1 0 0 1 0 1 0]\n","True:[0 1 0 0 1 0 1 0]\n","5 + 69 = 74\n","------------\n","iters:4300\n","Loss:0.0010515140691154798\n","Pred:[1 0 0 0 0 0 1 1]\n","True:[1 0 0 0 0 0 1 1]\n","33 + 98 = 131\n","------------\n","iters:4400\n","Loss:0.0025235946724460655\n","Pred:[1 0 0 0 0 0 1 0]\n","True:[1 0 0 0 0 0 1 0]\n","20 + 110 = 130\n","------------\n","iters:4500\n","Loss:0.0005942864019453133\n","Pred:[0 1 1 0 0 0 0 1]\n","True:[0 1 1 0 0 0 0 1]\n","18 + 79 = 97\n","------------\n","iters:4600\n","Loss:0.0012749451342231695\n","Pred:[0 1 1 1 0 0 0 0]\n","True:[0 1 1 1 0 0 0 0]\n","75 + 37 = 112\n","------------\n","iters:4700\n","Loss:0.0011489965832741755\n","Pred:[0 0 1 1 1 1 1 1]\n","True:[0 0 1 1 1 1 1 1]\n","21 + 42 = 63\n","------------\n","iters:4800\n","Loss:0.0001602695772903966\n","Pred:[0 1 1 0 1 1 0 0]\n","True:[0 1 1 0 1 1 0 0]\n","64 + 44 = 108\n","------------\n","iters:4900\n","Loss:0.0029471773030833107\n","Pred:[0 1 0 1 0 0 0 1]\n","True:[0 1 0 1 0 0 0 1]\n","35 + 46 = 81\n","------------\n","iters:5000\n","Loss:0.0015706716697676862\n","Pred:[1 0 0 1 0 1 1 0]\n","True:[1 0 0 1 0 1 1 0]\n","118 + 32 = 150\n","------------\n","iters:5100\n","Loss:0.004633628624932698\n","Pred:[0 0 1 1 0 1 0 0]\n","True:[0 0 1 1 0 1 0 0]\n","52 + 0 = 52\n","------------\n","iters:5200\n","Loss:0.0005146857900207425\n","Pred:[1 0 0 1 0 0 0 0]\n","True:[1 0 0 1 0 0 0 0]\n","73 + 71 = 144\n","------------\n","iters:5300\n","Loss:0.002431870778943526\n","Pred:[1 0 1 1 0 0 1 1]\n","True:[1 0 1 1 0 0 1 1]\n","123 + 56 = 179\n","------------\n","iters:5400\n","Loss:0.0007955071832819037\n","Pred:[0 1 0 1 1 1 0 1]\n","True:[0 1 0 1 1 1 0 1]\n","69 + 24 = 93\n","------------\n","iters:5500\n","Loss:0.00033834367915405603\n","Pred:[1 0 1 0 0 0 1 0]\n","True:[1 0 1 0 0 0 1 0]\n","42 + 120 = 162\n","------------\n","iters:5600\n","Loss:0.0024558056491647507\n","Pred:[0 1 1 1 0 0 0 1]\n","True:[0 1 1 1 0 0 0 1]\n","85 + 28 = 113\n","------------\n","iters:5700\n","Loss:0.00023877601648708584\n","Pred:[0 1 1 0 0 0 1 0]\n","True:[0 1 1 0 0 0 1 0]\n","3 + 95 = 98\n","------------\n","iters:5800\n","Loss:0.0010632501589221872\n","Pred:[1 0 1 0 0 0 0 1]\n","True:[1 0 1 0 0 0 0 1]\n","103 + 58 = 161\n","------------\n","iters:5900\n","Loss:0.0009308804449683599\n","Pred:[0 1 1 0 0 0 1 0]\n","True:[0 1 1 0 0 0 1 0]\n","0 + 98 = 98\n","------------\n","iters:6000\n","Loss:0.0006508064412014312\n","Pred:[0 1 0 1 1 0 1 1]\n","True:[0 1 0 1 1 0 1 1]\n","16 + 75 = 91\n","------------\n","iters:6100\n","Loss:0.011283964406518231\n","Pred:[0 1 0 0 0 0 0 0]\n","True:[0 1 0 0 0 0 0 0]\n","39 + 25 = 64\n","------------\n","iters:6200\n","Loss:0.00230436629677449\n","Pred:[0 0 0 1 1 1 1 1]\n","True:[0 0 0 1 1 1 1 1]\n","3 + 28 = 31\n","------------\n","iters:6300\n","Loss:0.0018623560805428759\n","Pred:[1 0 1 1 0 0 0 0]\n","True:[1 0 1 1 0 0 0 0]\n","125 + 51 = 176\n","------------\n","iters:6400\n","Loss:7.745408882064705e-05\n","Pred:[0 1 1 1 1 1 1 1]\n","True:[0 1 1 1 1 1 1 1]\n","52 + 75 = 127\n","------------\n","iters:6500\n","Loss:0.0007850338632182039\n","Pred:[1 0 0 0 0 1 0 0]\n","True:[1 0 0 0 0 1 0 0]\n","123 + 9 = 132\n","------------\n","iters:6600\n","Loss:0.000736370219551375\n","Pred:[0 1 1 1 0 0 1 0]\n","True:[0 1 1 1 0 0 1 0]\n","53 + 61 = 114\n","------------\n","iters:6700\n","Loss:0.0003680982532559007\n","Pred:[0 1 0 0 1 0 1 0]\n","True:[0 1 0 0 1 0 1 0]\n","3 + 71 = 74\n","------------\n","iters:6800\n","Loss:0.001102373285961837\n","Pred:[0 0 1 1 1 1 0 0]\n","True:[0 0 1 1 1 1 0 0]\n","12 + 48 = 60\n","------------\n","iters:6900\n","Loss:0.00022200028577573107\n","Pred:[1 0 1 1 1 0 0 0]\n","True:[1 0 1 1 1 0 0 0]\n","102 + 82 = 184\n","------------\n","iters:7000\n","Loss:0.004433998390224391\n","Pred:[0 1 0 1 1 0 0 0]\n","True:[0 1 0 1 1 0 0 0]\n","85 + 3 = 88\n","------------\n","iters:7100\n","Loss:0.00015424016246492719\n","Pred:[1 0 0 1 1 1 0 0]\n","True:[1 0 0 1 1 1 0 0]\n","91 + 65 = 156\n","------------\n","iters:7200\n","Loss:0.0017683884850276713\n","Pred:[0 1 0 1 0 1 0 1]\n","True:[0 1 0 1 0 1 0 1]\n","28 + 57 = 85\n","------------\n","iters:7300\n","Loss:0.0016815565506288928\n","Pred:[0 1 0 1 1 1 1 1]\n","True:[0 1 0 1 1 1 1 1]\n","73 + 22 = 95\n","------------\n","iters:7400\n","Loss:6.851385554068302e-05\n","Pred:[0 1 1 1 1 0 0 0]\n","True:[0 1 1 1 1 0 0 0]\n","90 + 30 = 120\n","------------\n","iters:7500\n","Loss:0.0012518847554923562\n","Pred:[1 0 0 1 0 1 0 0]\n","True:[1 0 0 1 0 1 0 0]\n","104 + 44 = 148\n","------------\n","iters:7600\n","Loss:0.0001279767042421572\n","Pred:[0 1 0 1 0 1 1 0]\n","True:[0 1 0 1 0 1 1 0]\n","62 + 24 = 86\n","------------\n","iters:7700\n","Loss:0.00019024842728362082\n","Pred:[1 0 0 0 1 1 1 1]\n","True:[1 0 0 0 1 1 1 1]\n","83 + 60 = 143\n","------------\n","iters:7800\n","Loss:0.001808528835785647\n","Pred:[1 1 0 0 0 1 1 1]\n","True:[1 1 0 0 0 1 1 1]\n","103 + 96 = 199\n","------------\n","iters:7900\n","Loss:0.0003474797852258306\n","Pred:[0 0 0 1 1 0 0 0]\n","True:[0 0 0 1 1 0 0 0]\n","18 + 6 = 24\n","------------\n","iters:8000\n","Loss:0.0005097902692488801\n","Pred:[1 1 0 0 0 1 0 1]\n","True:[1 1 0 0 0 1 0 1]\n","120 + 77 = 197\n","------------\n","iters:8100\n","Loss:0.00014180792797986288\n","Pred:[0 1 0 1 1 1 0 0]\n","True:[0 1 0 1 1 1 0 0]\n","27 + 65 = 92\n","------------\n","iters:8200\n","Loss:0.002405264443657009\n","Pred:[0 0 1 0 0 1 0 1]\n","True:[0 0 1 0 0 1 0 1]\n","34 + 3 = 37\n","------------\n","iters:8300\n","Loss:0.00025762414279950857\n","Pred:[1 0 1 0 0 1 0 1]\n","True:[1 0 1 0 0 1 0 1]\n","77 + 88 = 165\n","------------\n","iters:8400\n","Loss:0.00013566593259694602\n","Pred:[1 1 1 1 0 0 0 1]\n","True:[1 1 1 1 0 0 0 1]\n","127 + 114 = 241\n","------------\n","iters:8500\n","Loss:0.0007753630286565552\n","Pred:[1 0 1 1 0 0 0 1]\n","True:[1 0 1 1 0 0 0 1]\n","71 + 106 = 177\n","------------\n","iters:8600\n","Loss:0.0003319128312337609\n","Pred:[0 0 1 0 0 1 1 1]\n","True:[0 0 1 0 0 1 1 1]\n","30 + 9 = 39\n","------------\n","iters:8700\n","Loss:0.00019670985494424224\n","Pred:[1 1 0 0 0 1 1 0]\n","True:[1 1 0 0 0 1 1 0]\n","114 + 84 = 198\n","------------\n","iters:8800\n","Loss:9.583560339521531e-05\n","Pred:[0 1 0 1 0 0 1 1]\n","True:[0 1 0 1 0 0 1 1]\n","1 + 82 = 83\n","------------\n","iters:8900\n","Loss:0.0002577530486254342\n","Pred:[0 0 0 0 1 0 1 1]\n","True:[0 0 0 0 1 0 1 1]\n","10 + 1 = 11\n","------------\n","iters:9000\n","Loss:0.0015109945541917468\n","Pred:[0 1 0 1 0 1 0 0]\n","True:[0 1 0 1 0 1 0 0]\n","38 + 46 = 84\n","------------\n","iters:9100\n","Loss:5.7609089857908166e-05\n","Pred:[1 0 0 0 0 1 1 1]\n","True:[1 0 0 0 0 1 1 1]\n","66 + 69 = 135\n","------------\n","iters:9200\n","Loss:0.00012266873659097562\n","Pred:[0 1 0 0 1 1 1 0]\n","True:[0 1 0 0 1 1 1 0]\n","64 + 14 = 78\n","------------\n","iters:9300\n","Loss:0.001924072913211924\n","Pred:[0 1 0 0 1 0 0 1]\n","True:[0 1 0 0 1 0 0 1]\n","68 + 5 = 73\n","------------\n","iters:9400\n","Loss:0.00011066240291280604\n","Pred:[1 1 0 1 1 1 0 1]\n","True:[1 1 0 1 1 1 0 1]\n","100 + 121 = 221\n","------------\n","iters:9500\n","Loss:0.001374296616947735\n","Pred:[0 1 1 0 1 0 0 1]\n","True:[0 1 1 0 1 0 0 1]\n","91 + 14 = 105\n","------------\n","iters:9600\n","Loss:0.0018828791376112183\n","Pred:[1 0 1 0 0 0 1 1]\n","True:[1 0 1 0 0 0 1 1]\n","126 + 37 = 163\n","------------\n","iters:9700\n","Loss:0.0010633069550420172\n","Pred:[0 0 1 1 0 1 1 1]\n","True:[0 0 1 1 0 1 1 1]\n","50 + 5 = 55\n","------------\n","iters:9800\n","Loss:7.057177708105498e-05\n","Pred:[0 1 1 1 0 0 1 1]\n","True:[0 1 1 1 0 0 1 1]\n","105 + 10 = 115\n","------------\n","iters:9900\n","Loss:0.0015277265972706768\n","Pred:[0 0 0 1 1 0 0 1]\n","True:[0 0 0 1 1 0 0 1]\n","1 + 24 = 25\n","------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}