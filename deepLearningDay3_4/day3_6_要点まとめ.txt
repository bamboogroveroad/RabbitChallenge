RNNでは、単語のような可変長の文字列をNNに与えることはできない、
→固定長形式で単語を表す必要がある課題

●word2vecは、単語を、ベクトル(embedding表現)に表現する手法
（＊One-Hotベクトルからembedding表現に変換する時に変換表を用いるが,変換表を学習させる）

学習データからボキャブラリを作成
※わかりやすく7語のボキャブラリを作成したら、本来は辞書の単号数だけできあがる。
I like eat apples.I like an apple.
→｛apples,eat,I,like,to,want｝

Applesを入力する場合は、入力層には以下のベクトルが入力される、
※本来は辞書の単号数だけできあがる。
----------------
1...apples
0...eat
0...I
0...like
0...to
・
・
・
-----------

・メリット
大規模データの分散表現の学習が現実的な計算速度とメモリ量で実現可能にした。


ボキャブラリ×任意の単語ベクトル次元で重み行列が作成
