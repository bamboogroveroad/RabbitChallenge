●MobileNet　画像認識のモデルで軽量化したモデル
→軽くて性能が良い良いモデルの先駆け。あまり計算量を増やさずに比較的高性能である事が目標。

・MobileNetは畳み込み演算を2つの工夫をして、
一般的な畳み込みレイヤの計算量（ストライド1でパディングを適用した場合の畳み込み計算の計算量）を少なくしている。

〇Depthwise Convolution　
・フィルタ数は1つ
・入力マップのチャネルごとに畳み込みを実施
・出力マップをそれらと結合(入力マップのチャネル数と同じになる) 
・通常の畳み込みカーネルはすべての層にかかっていることを考えると計算量が大幅に削減可能
・各層ごとの畳み込みなので層間の関係性は考慮されない。通常はPW畳み込みとセットで使うことで解決

〇Pointwise Convolution
・1×1convとも呼ばれる（正確には1×1×c）
・入力マップのポイントごとに畳み込みを実施
・出力マップ（チャネル数）はフィルタ数分だけ作成可能（任意のサイズが指定可能）

--------------------------------------------------------------------------------------------------------
●DenseNet　画像認識のネットワーク

〇DenseBlock
・出力層に前の層の入力を足し合わせる
（層間の情報伝達を最大にするために,すべての同特徴量サイズの層を結合する）

具体的な処理は下記
・特徴マップの入力には、前の層の結果も付け加えられている
・Batch正規化
・Relu関数による返還
・3×3畳み込み層による処理

kチャネルを出力する畳み込みを行っているとしたら、
1層通過するごとにkチャネル数が増加していく。
→kが大きくなるほど、ネットワークが大きくなるため、小さな整数に設定するのが良い。
（上記のkは、ネットワークのgrowth rate(成長率)と呼ばれるハイパーパラメータ）

〇Transition Layer（各DenseBlockの間にあり、ConvolutionとPooling処理をするレイヤー）
CNNでは中間層でチャネルサイズを変更し、特徴マップのサイズを変更し、ダウンサンプリングを行うため、
Transition Layerと呼ばれる層でDenceblockをつなぐ
そのため、各DenseBlock内では特徴マップのサイズは一致している。

※DenseNetとResNetの違いについて
・DenseBlockでは前方の各層からの出力全てが後方の層への入力として用いられる
・RessidualBlockでは前1層の入力のみ後方の層へ入力。

--------------------------------------------------------------------------------------------------------

●BatchNorm
・レイヤー間を流れるデータの分布をミニバッチ単位で平均が0・分散が1になるように正規化
・Batch NormalizationはNNにおいて学習時間の短縮や初期値への依存軽減、過学習の抑制等の効果がある。

・問題点として、BatchSizeが小さい条件下では、学習が収束しないことがあり、代わりにLayer Normalization等の
正規化手法が使われることが多い。
・また、そもそもミニバッチのサイズは処理する演算機の性能に依存するため、効果が追えずに実験にならない。

〇BatchNormとそれ以外の正規化比較

BatchNorm　　ミニバッチに含まれるsampleの同一チャネルが同一分布に従うよう正規化
LayerNorm　　それぞれのsampleの全てのpixelsが同一分布に従うよう正規化
InstanceNorm さらにchannelも同一分布に従うよう正規化（各sampleの各チャネルごとに正規化）
（ミニバッチの大きさの影響を受けるは、BatchNormのみ）

●LayerNorm
普通に考えるとBatchNormというのは正規化の方法としては順当だがミニバッチの問題があったため、
LayerNormのような全てのチャネルの平均と分散を求め正規化する手法が、普通に用いられている。
また、LayerNormは、入力データのスケールのスケールに関してロバスト、重み行列のスケールやシフトに関してロバストであり、
出力が変わらないことが知られている

●InstanceNorm
各々の画像中の1つ1つのチャネルの中だけで正規化をしてあげる。赤なら赤、青なら青というように各チャネルだけで正規化を行う。
このようにばらばらに各チャネルで正規化を行ったとしても、画像のスタイル転送やテクスチャの合成というタスクでは上手く行く。

--------------------------------------------------------------------------------------------------------

●Wavenet(音声生成モデル)
・時系列データに対して畳み込み（Dilated　convolution）を適用する。
・Dilated　convolution
　層が深くなるにつれて畳み込むリンクを離す(例えばDilated = 1,2,4,8)。こうすることで、受容野を簡単に増やすことができるという利点がある。